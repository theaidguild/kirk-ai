{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"kirk-ai","text":"<p>kirk-ai is a compact command-line interface crafted to interact with Ollama AI models. This site provides guided documentation to get you started quickly, explain the architecture, and help you integrate <code>kirk-ai</code> into your workflows.</p>"},{"location":"#quick-links","title":"Quick links","text":"<ul> <li>Installation</li> <li>Usage</li> <li>Commands</li> <li>Architecture</li> <li>Contributing</li> </ul>"},{"location":"#why-kirk-ai","title":"Why kirk-ai?","text":"<ul> <li>Minimal, focused CLI for model interactions</li> <li>Clear separation between API client, templates and commands</li> <li>Lightweight and easily extensible</li> </ul>"},{"location":"#example-quick-chat","title":"Example \u2014 quick chat","text":"<pre><code>./kirk-ai chat \"Hello \u2014 what's new?\"\n</code></pre> <p>This repository is designed for contributors and users alike. Use the sidebar to navigate deeper sections or search from the top bar.</p>"},{"location":"#project-goal-a-tpusa-specialized-ai","title":"Project goal: a TPUSA-specialized AI","text":"<p>This project aims to demonstrate a focused documentation and retrieval assistant specialized for content related to Turning Point USA (TPUSA). The site and codebase include a research dataset collected under <code>tpusa_crawl/</code> and precomputed embeddings in <code>final_embeddings.json</code> which were produced to support retrieval-augmented tasks such as search, summarization, and question-answering tailored to the collected corpus.</p> <p>Key points:</p> <ul> <li>Data provenance: the corpus used for this project comes from publicly available TPUSA pages and related materials stored under <code>tpusa_crawl/</code> in this repository. The precomputed vectors are available in <code>final_embeddings.json</code> for reproducibility and experimentation.</li> <li>Intended capabilities: the specialized AI is intended as a retrieval-augmented assistant for discovery, context-aware summarization, and example-driven code generation tied to the collected materials. It is not intended as an official TPUSA product and the repository is not affiliated with TPUSA.</li> <li>Limitations &amp; ethics: the model reflects the content of the source corpus and therefore inherits its biases and perspectives. Before using outputs in public-facing or decision-making contexts, verify claims against primary sources and consider legal and ethical constraints. Do not use the system to create targeted political persuasion; use it for research, archival, or neutral summarization tasks.</li> <li>Reproducibility: processing scripts and the data pipeline are organized under <code>tools/</code> and <code>tpusa_crawl/</code>. See the dedicated page \"TPUSA AI\" in the documentation for step-by-step notes on reproducing the dataset and embeddings.</li> </ul>"},{"location":"architecture/","title":"Architecture","text":"<p>kirk-ai is organized to keep responsibilities separated and the codebase easy to reason about.</p> <ul> <li><code>cmd/</code> \u2014 CLI command definitions and wiring (Cobra)</li> <li><code>internal/client</code> \u2014 HTTP client for Ollama interactions</li> <li><code>internal/templates</code> \u2014 Prompt templates used for code generation tasks</li> <li><code>internal/models</code> \u2014 Request/response structs</li> </ul> <p>The CLI follows a simple flow: parse flags \u2192 select model \u2192 call client \u2192 format output.</p>"},{"location":"architecture/#extending-the-cli","title":"Extending the CLI","text":"<p>Add a new command under <code>cmd/</code> and register it in <code>root.go</code>. Use existing helpers for model selection and error handling to keep behavior consistent.</p>"},{"location":"commands/","title":"Commands","text":"<p>This project uses Cobra for CLI command structure. Below are examples and common flags.</p>"},{"location":"commands/#chat","title":"chat","text":"<p>Use the <code>chat</code> command to send prompts to a selected model.</p> <pre><code>./kirk-ai chat \"Write a short poem about the sea\"\n</code></pre> <p>Flags: - <code>--model</code> \u2014 specify model name - <code>--verbose</code> \u2014 show metadata</p>"},{"location":"commands/#embed","title":"embed","text":"<p>Generate embeddings for text snippets.</p> <pre><code>./kirk-ai embed \"Document text to embed\"\n</code></pre>"},{"location":"commands/#models","title":"models","text":"<p>List models available from the Ollama server.</p> <pre><code>./kirk-ai models\n</code></pre>"},{"location":"commands/#code","title":"code","text":"<p>Generate code snippets or helper functions using the recommended coding model.</p> <pre><code>./kirk-ai code \"Create a function that reverses a string\"\n</code></pre>"},{"location":"contributing/","title":"Contributing","text":"<p>Thanks for contributing! We welcome fixes, documentation improvements, and new features.</p>"},{"location":"contributing/#development-workflow","title":"Development workflow","text":"<ul> <li>Fork the repo and create a feature branch.</li> <li>Run <code>go fmt ./...</code> and <code>go vet ./...</code> before committing.</li> <li>Add tests alongside your code changes.</li> </ul>"},{"location":"contributing/#docs-contributions","title":"Docs contributions","text":"<ul> <li>Edit markdown files under <code>docs_src/</code>.</li> <li>Preview locally with <code>mkdocs serve -f mkdocs.yml</code>.</li> <li>Open a PR against <code>main</code> \u2014 the Pages CI pipeline will build and deploy the docs automatically.</li> </ul>"},{"location":"contributing/#reviewing","title":"Reviewing","text":"<p>Keep changes small and focused. For large changes, open an issue first to discuss the approach.</p>"},{"location":"installation/","title":"Installation","text":""},{"location":"installation/#requirements","title":"Requirements","text":"<ul> <li>Go 1.19 or higher</li> <li>Ollama (optional) for model-based features</li> </ul>"},{"location":"installation/#quickstart","title":"Quickstart","text":"<ol> <li>Clone the repository</li> </ol> <pre><code>git clone https://github.com/theaidguild/kirk-ai.git\ncd kirk-ai\n</code></pre> <ol> <li>Download dependencies and build</li> </ol> <pre><code>go mod download &amp;&amp; go mod tidy\n\ngo build -v .\n</code></pre> <ol> <li>Run locally</li> </ol> <pre><code>./kirk-ai --help\n</code></pre> <p>For documentation preview:</p> <pre><code>pip install -r docs_requirements.txt\nmkdocs serve -f mkdocs.yml\n</code></pre>"},{"location":"tpusa_ai/","title":"TPUSA AI \u2014 Project overview","text":"<p>This page documents the project's aim to build and experiment with an AI assistant specialized for content collected from TPUSA (Turning Point USA) public materials. It explains data sources, intended uses, reproducibility notes, and ethical constraints.</p>"},{"location":"tpusa_ai/#goals","title":"Goals","text":"<ul> <li>Produce a retrieval-augmented assistant that can search, summarize, and answer questions about the TPUSA corpus.</li> <li>Provide reproducible tooling and embeddings so others can verify methods and experiment with model choices.</li> <li>Document the processing pipeline and metadata for data provenance.</li> </ul>"},{"location":"tpusa_ai/#data-sources-provenance","title":"Data sources &amp; provenance","text":"<ul> <li>Raw pages and artifacts are stored under <code>tpusa_crawl/</code> in this repository. The dataset was collected from publicly accessible pages and is included here for research and documentation purposes.</li> <li>Precomputed embeddings are stored in <code>final_embeddings.json</code>. These were produced by a pipeline that chunks documents, sanitizes HTML/text, and calls an embedding model to produce vector representations for retrieval.</li> </ul>"},{"location":"tpusa_ai/#intended-capabilities","title":"Intended capabilities","text":"<p>The specialized AI is designed for:</p> <ul> <li>Retrieval: fast, vector-based search over the corpus using the provided embeddings.</li> <li>Summarization: generate concise summaries of individual pages or clusters of pages.</li> <li>Contextual Q&amp;A: answer factual questions by retrieving the most relevant passages and generating grounded responses.</li> </ul>"},{"location":"tpusa_ai/#limitations-responsible-use","title":"Limitations &amp; responsible use","text":"<ul> <li>The assistant reflects the content and biases present in the source documents. Verify model outputs before presenting them as fact.</li> <li>Do not use the assistant to generate targeted political persuasion or microtargeted campaigning. This project is intended for research, archival, and neutral summarization and discovery tasks only.</li> <li>Respect copyright and privacy: only use or publish material you have the rights to share, and follow applicable terms of service for the sources.</li> </ul>"},{"location":"tpusa_ai/#reproducibility-pipeline","title":"Reproducibility &amp; pipeline","text":"<ul> <li>The repository contains tooling under <code>tools/processor/</code> and <code>scripts/</code> used to crawl, clean, and produce embeddings. Typical steps:</li> <li>Run the crawler to collect raw HTML (stored under <code>tpusa_crawl/raw_html/</code>).</li> <li>Run the content processor to chunk and clean text.</li> <li> <p>Produce embeddings for each chunk and store them (the resulting vectors are combined into <code>final_embeddings.json</code>).</p> </li> <li> <p>See <code>tools/processor/prepare_embeddings_data.go</code> and other helper scripts for implementation details. If you want me to add a single-command script or Make target that reproduces the pipeline, I can add it.</p> </li> </ul>"},{"location":"tpusa_ai/#demo-video","title":"Demo video","text":"Your browser does not support HTML5 video playback. You can download the demo file instead: [Download demo](../assets/media/demo.mp4)."},{"location":"tpusa_ai/#contributing","title":"Contributing","text":"<ul> <li>If you add more sources or correct metadata, include provenance (original URL, crawl date) and add tests that verify text processing edge cases.</li> <li>Keep datasets and embeddings separated from private keys and avoid committing sensitive credentials.</li> </ul>"},{"location":"tpusa_ai/#contact-disclaimers","title":"Contact &amp; disclaimers","text":"<p>This project is not affiliated with or endorsed by Turning Point USA. If you represent the rights holder for any content included here and want it removed, open an issue or submit a DMCA request following standard GitHub procedures.</p>"},{"location":"usage/","title":"Usage","text":"<p>This section explains common usage patterns for <code>kirk-ai</code>.</p>"},{"location":"usage/#list-models","title":"List models","text":"<pre><code>./kirk-ai models\n</code></pre>"},{"location":"usage/#chat","title":"Chat","text":"<pre><code>./kirk-ai chat \"Hello! Tell me a joke\"\n</code></pre>"},{"location":"usage/#embeddings","title":"Embeddings","text":"<pre><code>./kirk-ai embed \"This is some text to embed\"\n</code></pre>"},{"location":"usage/#build-and-run","title":"Build and run","text":"<pre><code>go build -v .\n./kirk-ai --help\n</code></pre>"}]}